{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31aa0a8d",
   "metadata": {},
   "source": [
    "## Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07811750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b56344",
   "metadata": {},
   "source": [
    "### Reading Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93928359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_license_plate(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    # Make sure to provide the correct path to the haarcascade_russian_plate_number.xml file\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Detect license plates in the image\n",
    "    plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around detected license plates\n",
    "    for (x, y, w, h) in plates:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('License Plate Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35de007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the path to your image\n",
    "detect_license_plate('etios.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d9ead",
   "metadata": {},
   "source": [
    "## Easy OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624812c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "def detect_license_plate_live():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Create an EasyOCR reader instance\n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    plate_text = None\n",
    "    max_confidence = 0\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected license plate\n",
    "        for (x, y, w, h) in plates:\n",
    "            # Extract the license plate region from the frame\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Use EasyOCR to read text from the license plate region\n",
    "            results = reader.readtext(plate_roi)\n",
    "\n",
    "            # Find the text with the highest confidence\n",
    "            for result in results:\n",
    "                if result[2] > max_confidence:\n",
    "                    max_confidence = result[2]\n",
    "                    plate_text = result[1]\n",
    "\n",
    "            # Draw a rectangle around the license plate\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Print the most accurate plate text\n",
    "        if plate_text is not None:\n",
    "            print(\"Detected Plate Text:\", plate_text)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "detect_license_plate_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c13a27",
   "metadata": {},
   "source": [
    "## Printing Only One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "def detect_license_plate_live():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Create an EasyOCR reader instance\n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    plate_text = None\n",
    "    max_confidence = 0\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected license plate\n",
    "        for (x, y, w, h) in plates:\n",
    "            # Extract the license plate region from the frame\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Use EasyOCR to read text from the license plate region\n",
    "            results = reader.readtext(plate_roi)\n",
    "\n",
    "            # Find the text with the highest confidence\n",
    "            for result in results:\n",
    "                if result[2] > max_confidence:\n",
    "                    max_confidence = result[2]\n",
    "                    plate_text = result[1]\n",
    "\n",
    "            # Draw a rectangle around the license plate\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Print the most accurate plate text\n",
    "        if plate_text is not None:\n",
    "            print(plate_text)\n",
    "            break\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "detect_license_plate_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ca39d",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import re\n",
    "\n",
    "def detect_license_plate_live():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Create an EasyOCR reader instance\n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected license plate\n",
    "        for (x, y, w, h) in plates:\n",
    "            # Extract the license plate region from the frame\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Use EasyOCR to read text from the license plate region\n",
    "            results = reader.readtext(plate_roi)\n",
    "\n",
    "            # Filter out the plate text ending with 4 numbers\n",
    "            for result in results:\n",
    "                plate_text = result[1]\n",
    "                if re.match(r'.*\\d{4}$', plate_text):\n",
    "                    # Draw a rectangle around the license plate\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                    \n",
    "                    # Print the plate text\n",
    "                    print(plate_text)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "detect_license_plate_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1d1c3",
   "metadata": {},
   "source": [
    "## Regex + Max Confindence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import re\n",
    "\n",
    "def detect_license_plate_live():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Create an EasyOCR reader instance\n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Lists to store plate texts and confidences\n",
    "        plate_texts = []\n",
    "        confidences = []\n",
    "\n",
    "        # Process each detected license plate\n",
    "        for (x, y, w, h) in plates:\n",
    "            # Extract the license plate region from the frame\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Use EasyOCR to read text from the license plate region\n",
    "            results = reader.readtext(plate_roi)\n",
    "\n",
    "            # Filter out the plate text ending with 4 numbers\n",
    "            for result in results:\n",
    "                plate_text = result[1]\n",
    "                confidence = result[2]\n",
    "                if re.match(r'.*\\d{4}$', plate_text):\n",
    "                    plate_texts.append(plate_text)\n",
    "                    confidences.append(confidence)\n",
    "\n",
    "                    # Draw a rectangle around the license plate\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Print the plate text with the maximum confidence\n",
    "        if confidences:\n",
    "            max_confidence_index = confidences.index(max(confidences))\n",
    "            max_confidence_plate_text = plate_texts[max_confidence_index]\n",
    "            print(\"Plate text with max confidence:\", max_confidence_plate_text)\n",
    "            break\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "detect_license_plate_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d48ca0",
   "metadata": {},
   "source": [
    "## Google OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from base64 import b64encode\n",
    "from IPython.display import Image\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3210f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestOCR(url, api_key, imgpath):\n",
    "  imgdata = makeImageData(imgpath)\n",
    "  response = requests.post(ENDPOINT_URL, \n",
    "                           data = imgdata, \n",
    "                           params = {'key': api_key}, \n",
    "                           headers = {'Content-Type': 'application/json'})\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d77884",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vision_api.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "api_key = data[\"key\"]\n",
    "img_loc = \"audi.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77998d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdc406",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requestOCR(ENDPOINT_URL, api_key, img_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181da5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.status_code != 200 or result.json().get('error'):\n",
    "    print (\"Error\")\n",
    "else:\n",
    "    result = result.json()['responses'][0]['textAnnotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(result)):\n",
    "    description = result[index][\"description\"]\n",
    "    description_without_spaces = description.replace(\" \", \"\")\n",
    "    a = len(description_without_spaces)\n",
    "    print(description_without_spaces, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28278c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(result)):\n",
    "    description = result[index][\"description\"]\n",
    "    description_without_spaces = description.replace(\" \", \"\")\n",
    "    \n",
    "    if len(description_without_spaces) == 10:\n",
    "        print(description_without_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cord(result):\n",
    "  cord_df = pd.DataFrame(result['boundingPoly']['vertices'])\n",
    "  x_min, y_min = np.min(cord_df[\"x\"]), np.min(cord_df[\"y\"])\n",
    "  x_max, y_max = np.max(cord_df[\"x\"]), np.max(cord_df[\"y\"])\n",
    "  return result[\"description\"], x_max, x_min, y_max, y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb616166",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_max, x_min, y_max, y_min = gen_cord(result[-1])\n",
    "image = cv2.imread(img_loc)\n",
    "cv2.rectangle(image,(x_min,y_min),(x_max,y_max),(0,255, 0),2)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "print (\"Text Detected = {}\".format(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bf97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b311c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from base64 import b64encode\n",
    "from IPython.display import Image\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 20\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    if result.status_code != 200 or result.json().get('error'):\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    else:\n",
    "        result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "    final_description = ''\n",
    "    for index in range(len(result)):\n",
    "        description = result[index][\"description\"]\n",
    "        description_without_spaces = description.replace(\" \", \"\")\n",
    "        \n",
    "        if len(description_without_spaces) == 10 and \\\n",
    "           description_without_spaces[:2].isalpha() and \\\n",
    "           description_without_spaces[-4:].isdigit():\n",
    "            final_description = description_without_spaces\n",
    "\n",
    "    return description_without_spaces\n",
    "\n",
    "img_loc = \"cropped_images/cropped_plate_20240315190305.jpg\"\n",
    "\n",
    "final_text = process_image(img_loc)\n",
    "if final_text:\n",
    "    print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcd486",
   "metadata": {},
   "source": [
    "## Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da735f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def detect_and_crop_license_plate_from_webcam():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Start capturing video from the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Create a directory to store the cropped images if it doesn't exist\n",
    "    if not os.path.exists('cropped_images'):\n",
    "        os.makedirs('cropped_images')\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected license plates\n",
    "        for (x, y, w, h) in plates:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Crop the detected license plate region\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Generate a unique filename using current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f'cropped_images/cropped_plate_{timestamp}.jpg'\n",
    "\n",
    "            # Save the cropped license plate image\n",
    "            cv2.imwrite(filename, plate_roi)\n",
    "            print(f\"Saved {filename}\")\n",
    "\n",
    "        # Display the frame with license plate detection\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function to start license plate detection, cropping, and saving from webcam\n",
    "detect_and_crop_license_plate_from_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6529e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from base64 import b64encode\n",
    "from IPython.display import Image\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 20\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    try:\n",
    "        if result.status_code != 200 or result.json().get('error'):\n",
    "            print(f\"Error processing image: {image_location}\")\n",
    "            return None\n",
    "        else:\n",
    "            result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "        final_description = ''\n",
    "        for index in range(len(result)):\n",
    "            description = result[index][\"description\"]\n",
    "            description_without_spaces = description.replace(\" \", \"\")\n",
    "            \n",
    "            if len(description_without_spaces) == 10 and \\\n",
    "               description_without_spaces[:2].isalpha() and \\\n",
    "               description_without_spaces[-4:].isdigit():\n",
    "                final_description = description_without_spaces\n",
    "\n",
    "        return final_description\n",
    "    except KeyError:\n",
    "#         print(f\"No textAnnotations found in image: {image_location}\")\n",
    "        return None\n",
    "\n",
    "# Process all images in the cropped_images directory\n",
    "cropped_images_dir = \"cropped_images\"\n",
    "unique_texts = []\n",
    "\n",
    "for filename in os.listdir(cropped_images_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_loc = os.path.join(cropped_images_dir, filename)\n",
    "        final_text = process_image(img_loc)\n",
    "        if final_text and final_text not in unique_texts:\n",
    "            unique_texts.append(final_text)\n",
    "\n",
    "# Print the list of unique final_text values\n",
    "for text in unique_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91363ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531c545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "from base64 import b64encode\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Global variables\n",
    "unique_texts = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def detect_and_crop_license_plate_from_webcam():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Start capturing video from the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected license plates\n",
    "        for (x, y, w, h) in plates:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Crop the detected license plate region\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Generate a unique filename using current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f'cropped_images/cropped_plate_{timestamp}.jpg'\n",
    "\n",
    "            # Save the cropped license plate image\n",
    "            cv2.imwrite(filename, plate_roi)\n",
    "#             print(f\"Saved {filename}\")\n",
    "\n",
    "            # Start a new thread for OCR processing\n",
    "            threading.Thread(target=process_image, args=(filename,)).start()\n",
    "\n",
    "        # Display the frame with license plate detection\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    try:\n",
    "        if result.status_code != 200 or result.json().get('error'):\n",
    "#             print(f\"Error processing image: {image_location}\")\n",
    "            return None\n",
    "        else:\n",
    "            result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "        final_description = ''\n",
    "        for index in range(len(result)):\n",
    "            description = result[index][\"description\"]\n",
    "            description_without_spaces = description.replace(\" \", \"\")\n",
    "            \n",
    "            if len(description_without_spaces) == 10 and \\\n",
    "               description_without_spaces[:2].isalpha() and \\\n",
    "               description_without_spaces[-4:].isdigit() and \\\n",
    "               description_without_spaces[2:4].isdigit() and \\\n",
    "               description_without_spaces[4:6].isalpha():\n",
    "                final_description = description_without_spaces\n",
    "\n",
    "        with lock:\n",
    "            if final_description and final_description not in unique_texts:\n",
    "                unique_texts.append(final_description)\n",
    "\n",
    "        return final_description\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Call the function to start license plate detection and OCR processing from webcam\n",
    "detect_and_crop_license_plate_from_webcam()\n",
    "\n",
    "# Print the list of unique final_text values\n",
    "for text in unique_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f433cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ff9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspected_plate = input(\"Enter the suspected plate: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store potential matches\n",
    "potential_matches = []\n",
    "\n",
    "# Iterate through the unique texts list\n",
    "for text in unique_texts:\n",
    "  # Check for exact match\n",
    "    if text == suspected_plate:\n",
    "        # If exact match, add it to the list and break the loop\n",
    "        potential_matches.append(text)\n",
    "        break;\n",
    "        \n",
    "if len(potential_matches) == 0:\n",
    "    # Check for approximate match (7 out of 10 characters similar)\n",
    "    for match in unique_texts:\n",
    "        count = 0\n",
    "        for i in range(10):\n",
    "            if suspected_plate[i] == match[i]:\n",
    "                count += 1\n",
    "        if (count >= 7):\n",
    "            potential_matches.append(match)\n",
    "\n",
    "# Print the potential matches\n",
    "print(\"Potential Matches:\", potential_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8d370",
   "metadata": {},
   "source": [
    "## Detect & Print Potential Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e1fd88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the suspected plate: MH43CC1745\n",
      "MH20DV2366\n",
      "MH20DY2366\n",
      "NH20DY2366\n",
      "MH43CC1745\n",
      "NH43CC1745\n",
      "Potential Matches: ['MH43CC1745']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "from base64 import b64encode\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Global variables\n",
    "unique_texts = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "suspected_plate = input(\"Enter the suspected plate: \")\n",
    "\n",
    "def detect_and_crop_license_plate_from_webcam():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Start capturing video from the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected license plates\n",
    "        for (x, y, w, h) in plates:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Crop the detected license plate region\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Generate a unique filename using current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f'cropped_images/cropped_plate_{timestamp}.jpg'\n",
    "\n",
    "            # Save the cropped license plate image\n",
    "            cv2.imwrite(filename, plate_roi)\n",
    "\n",
    "            # Start a new thread for OCR processing\n",
    "            threading.Thread(target=process_image, args=(filename,)).start()\n",
    "\n",
    "        # Display the frame with license plate detection\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    try:\n",
    "        if result.status_code != 200 or result.json().get('error'):\n",
    "            return None\n",
    "        else:\n",
    "            result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "        final_description = ''\n",
    "        for index in range(len(result)):\n",
    "            description = result[index][\"description\"]\n",
    "            description_without_spaces = description.replace(\" \", \"\")\n",
    "            \n",
    "            if len(description_without_spaces) == 10 and \\\n",
    "               description_without_spaces[:2].isalpha() and \\\n",
    "               description_without_spaces[-4:].isdigit() and \\\n",
    "               description_without_spaces[2:4].isdigit() and \\\n",
    "               description_without_spaces[4:6].isalpha():\n",
    "                final_description = description_without_spaces\n",
    "\n",
    "        with lock:\n",
    "            if final_description and final_description not in unique_texts:\n",
    "                unique_texts.append(final_description)\n",
    "\n",
    "        return final_description\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def find_potential_matches(suspected_plate):\n",
    "    # Initialize a list to store potential matches\n",
    "    potential_matches = []\n",
    "\n",
    "    # Iterate through the unique texts list\n",
    "    for text in unique_texts:\n",
    "        # Check for exact match\n",
    "        if text == suspected_plate:\n",
    "            # If exact match, add it to the list and break the loop\n",
    "            potential_matches.append(text)\n",
    "            break\n",
    "        \n",
    "    if len(potential_matches) == 0:\n",
    "        # Check for approximate match (7 out of 10 characters similar)\n",
    "        for match in unique_texts:\n",
    "            count = 0\n",
    "            for i in range(10):\n",
    "                if suspected_plate[i] == match[i]:\n",
    "                    count += 1\n",
    "            if count >= 7:\n",
    "                potential_matches.append(match)\n",
    "\n",
    "    return potential_matches\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function to start license plate detection and OCR processing from webcam\n",
    "    detect_and_crop_license_plate_from_webcam()\n",
    "\n",
    "    # Print the list of unique final_text values\n",
    "    for text in unique_texts:\n",
    "        print(text)\n",
    "\n",
    "    # Find potential matches for the suspected plate\n",
    "    matches = find_potential_matches(suspected_plate)\n",
    "\n",
    "    # Print the potential matches\n",
    "    print(\"Potential Matches:\", matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b29124",
   "metadata": {},
   "source": [
    "### Realtime Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b72962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "from base64 import b64encode\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Global variables\n",
    "unique_texts = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "suspected_plate = input(\"Enter the suspected plate: \")\n",
    "\n",
    "def detect_and_crop_license_plate_from_webcam():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Start capturing video from the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected license plates\n",
    "        for (x, y, w, h) in plates:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Crop the detected license plate region\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Generate a unique filename using current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f'cropped_images/cropped_plate_{timestamp}.jpg'\n",
    "\n",
    "            # Save the cropped license plate image\n",
    "            cv2.imwrite(filename, plate_roi)\n",
    "\n",
    "            # Start a new thread for OCR processing\n",
    "            threading.Thread(target=process_image, args=(filename,)).start()\n",
    "\n",
    "        # Display the frame with license plate detection\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    try:\n",
    "        if result.status_code != 200 or result.json().get('error'):\n",
    "            return None\n",
    "        else:\n",
    "            result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "        final_description = ''\n",
    "        for index in range(len(result)):\n",
    "            description = result[index][\"description\"]\n",
    "            description_without_spaces = description.replace(\" \", \"\")\n",
    "            \n",
    "            if len(description_without_spaces) == 10 and \\\n",
    "               description_without_spaces[:2].isalpha() and \\\n",
    "               description_without_spaces[-4:].isdigit() and \\\n",
    "               description_without_spaces[2:4].isdigit() and \\\n",
    "               description_without_spaces[4:6].isalpha():\n",
    "                final_description = description_without_spaces\n",
    "\n",
    "        with lock:\n",
    "            if final_description and final_description not in unique_texts:\n",
    "                unique_texts.append(final_description)\n",
    "\n",
    "        return final_description\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def find_potential_matches(suspected_plate):\n",
    "    # Initialize a list to store potential matches\n",
    "    potential_matches = []\n",
    "\n",
    "    # Iterate through the unique texts list\n",
    "    for text in unique_texts:\n",
    "        # Check for exact match\n",
    "        if text == suspected_plate:\n",
    "            # If exact match, add it to the list and print it\n",
    "            potential_matches.append(text)\n",
    "            print(\"Exact Match Found:\", text)\n",
    "            break\n",
    "\n",
    "    if len(potential_matches) == 0:\n",
    "        # Check for approximate match (7 out of 10 characters similar)\n",
    "        for match in unique_texts:\n",
    "            count = 0\n",
    "            for i in range(10):\n",
    "                if suspected_plate[i] == match[i]:\n",
    "                    count += 1\n",
    "            if count >= 7:\n",
    "                potential_matches.append(match)\n",
    "                print(\"Potential Match Found:\", match)\n",
    "\n",
    "    return potential_matches\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function to start license plate detection and OCR processing from webcam\n",
    "    detect_and_crop_license_plate_from_webcam()\n",
    "\n",
    "    # Print the list of unique final_text values\n",
    "    for text in unique_texts:\n",
    "        print(text)\n",
    "\n",
    "    # Find potential matches for the suspected plate\n",
    "    matches = find_potential_matches(suspected_plate)\n",
    "\n",
    "    # Print the potential matches\n",
    "    print(\"Potential Matches:\", matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fc20c",
   "metadata": {},
   "source": [
    "## Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c98fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "from base64 import b64encode\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Global variables\n",
    "unique_texts = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "suspected_plate = input(\"Enter the suspected plate: \")\n",
    "\n",
    "def detect_and_crop_license_plate_from_webcam():\n",
    "    # Load the pre-trained Haar Cascade classifier for license plates\n",
    "    plate_cascade = cv2.CascadeClassifier('haarcascade_plate_number.xml')\n",
    "\n",
    "    # Start capturing video from the webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect license plates in the frame\n",
    "        plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected license plates\n",
    "        for (x, y, w, h) in plates:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Crop the detected license plate region\n",
    "            plate_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Generate a unique filename using current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f'cropped_images/cropped_plate_{timestamp}.jpg'\n",
    "\n",
    "            # Save the cropped license plate image\n",
    "            cv2.imwrite(filename, plate_roi)\n",
    "\n",
    "            # Start a new thread for OCR processing\n",
    "            threading.Thread(target=process_image, args=(filename,)).start()\n",
    "\n",
    "        # Display the frame with license plate detection\n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Print the lists dynamically\n",
    "        print_lists()\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def makeImageData(imgpath):\n",
    "    img_req = None\n",
    "    with open(imgpath, 'rb') as f:\n",
    "        ctxt = b64encode(f.read()).decode()\n",
    "        img_req = {\n",
    "            'image': {\n",
    "                'content': ctxt\n",
    "            },\n",
    "            'features': [{\n",
    "                'type': 'DOCUMENT_TEXT_DETECTION',\n",
    "                'maxResults': 1\n",
    "            }]\n",
    "        }\n",
    "    return json.dumps({\"requests\": img_req}).encode()\n",
    "\n",
    "def requestOCR(url, api_key, imgpath):\n",
    "    imgdata = makeImageData(imgpath)\n",
    "    response = requests.post(url, \n",
    "                             data=imgdata, \n",
    "                             params={'key': api_key}, \n",
    "                             headers={'Content-Type': 'application/json'})\n",
    "    return response\n",
    "\n",
    "def process_image(image_location):\n",
    "    with open('vision_api.json') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    ENDPOINT_URL = 'https://vision.googleapis.com/v1/images:annotate'\n",
    "    api_key = data[\"key\"]\n",
    "    \n",
    "    result = requestOCR(ENDPOINT_URL, api_key, image_location)\n",
    "\n",
    "    try:\n",
    "        if result.status_code != 200 or result.json().get('error'):\n",
    "            return None\n",
    "        else:\n",
    "            result = result.json()['responses'][0]['textAnnotations']\n",
    "\n",
    "        final_description = ''\n",
    "        for index in range(len(result)):\n",
    "            description = result[index][\"description\"]\n",
    "            description_without_spaces = description.replace(\" \", \"\")\n",
    "            \n",
    "            if len(description_without_spaces) == 10 and \\\n",
    "               description_without_spaces[:2].isalpha() and \\\n",
    "               description_without_spaces[-4:].isdigit() and \\\n",
    "               description_without_spaces[2:4].isdigit() and \\\n",
    "               description_without_spaces[4:6].isalpha():\n",
    "                final_description = description_without_spaces\n",
    "\n",
    "        with lock:\n",
    "            if final_description and final_description not in unique_texts:\n",
    "                unique_texts.append(final_description)\n",
    "                print_lists()\n",
    "\n",
    "                # Check for potential matches\n",
    "                matches = find_potential_matches(suspected_plate)\n",
    "                if matches:\n",
    "                    print(\"Potential Matches:\", matches)\n",
    "                    break\n",
    "\n",
    "        return final_description\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def print_lists():\n",
    "    if unique_texts:\n",
    "        print(\"Unique Texts:\", unique_texts)\n",
    "\n",
    "def find_potential_matches(suspected_plate):\n",
    "    # Initialize a list to store potential matches\n",
    "    potential_matches = []\n",
    "\n",
    "    # Iterate through the unique texts list\n",
    "    for text in unique_texts:\n",
    "        # Check for exact match\n",
    "        if text == suspected_plate:\n",
    "            # If exact match, add it to the list and break the loop\n",
    "            potential_matches.append(text)\n",
    "            break\n",
    "        \n",
    "    if len(potential_matches) == 0:\n",
    "        # Check for approximate match (7 out of 10 characters similar)\n",
    "        for match in unique_texts:\n",
    "            count = 0\n",
    "            for i in range(10):\n",
    "                if suspected_plate[i] == match[i]:\n",
    "                    count += 1\n",
    "            if count >= 7:\n",
    "                potential_matches.append(match)\n",
    "\n",
    "    return potential_matches\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function to start license plate detection and OCR processing from webcam\n",
    "    detect_and_crop_license_plate_from_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb5a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
